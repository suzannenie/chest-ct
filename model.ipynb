{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone https://github.com/jfhealthcare/Chexpert and move CheXpert dataset inside this directory\n",
    "Inference for 5 classes with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzannenie/Library/Python/myvenv3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from easydict import EasyDict as edict\n",
    "import json\n",
    "from torch.nn import DataParallel\n",
    "from model.classifier import Classifier\n",
    "import time\n",
    "\n",
    "# model = torch.load(\"config/pre_train.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_path = \"config/example.json\"\n",
    "pre_train = \"config/pre_train.pth\"\n",
    "\n",
    "with open(cfg_path) as f:\n",
    "    cfg = edict(json.load(f))\n",
    "    # print(json.dumps(cfg, indent=4))\n",
    "\n",
    "# device_ids = list(map(int, args.device_ids.split(',')))\n",
    "device_ids = []\n",
    "num_devices = torch.cuda.device_count()\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda:{}'.format(device_ids[0]))\n",
    "\n",
    "model = Classifier(cfg)\n",
    "model = DataParallel(model, device_ids=device_ids).to(device).train()\n",
    "ckpt = torch.load(pre_train, map_location=device)\n",
    "model.module.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import ImageDataset\n",
    "import numpy as np\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    ImageDataset(cfg[\"dev_csv\"], cfg, mode='test'),\n",
    "    batch_size=1, num_workers=4,\n",
    "    drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "model.eval()\n",
    "device = torch.device('cpu')\n",
    "dataloader= dataloader_test\n",
    "steps = len(dataloader)\n",
    "dataiter = iter(dataloader)\n",
    "num_tasks = len(cfg.num_classes)\n",
    "txt_file = \"plot.txt\"\n",
    "\n",
    "test_header = [\n",
    "    'Path',\n",
    "    'Cardiomegaly',\n",
    "    'Edema',\n",
    "    'Consolidation',\n",
    "    'Atelectasis',\n",
    "    'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(output, cfg):\n",
    "    if cfg.criterion == 'BCE' or cfg.criterion == \"FL\":\n",
    "        for num_class in cfg.num_classes:\n",
    "            assert num_class == 1\n",
    "        pred = torch.sigmoid(output.view(-1)).cpu().detach().numpy()\n",
    "    elif cfg.criterion == 'CE':\n",
    "        for num_class in cfg.num_classes:\n",
    "            assert num_class >= 2\n",
    "        prob = F.softmax(output)\n",
    "        pred = prob[:, 1].cpu().detach().numpy()\n",
    "    else:\n",
    "        raise Exception('Unknown criterion : {}'.format(cfg.criterion))\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path,Cardiomegaly,Edema,Consolidation,Atelectasis,Pleural Effusion\n",
      "\n",
      "steps 234 num_tasks 5\n",
      "step  0\n",
      "CheXpert-v1.0-small/valid/patient64541/study1/view1_frontal.jpg,0.6085793375968933,0.5058494210243225,0.2419632077217102,0.45605579018592834,0.12261803448200226\n",
      "\n",
      "2022-10-01 00:34:06, Image : CheXpert-v1.0-small/valid/patient64541/study1/view1_frontal.jpg, Prob : 0.6085793375968933,0.5058494210243225,0.2419632077217102,0.45605579018592834,0.12261803448200226\n",
      "\n",
      "\n",
      "\n",
      "step  1\n",
      "CheXpert-v1.0-small/valid/patient64542/study1/view1_frontal.jpg,0.05178125575184822,0.1388433873653412,0.17289796471595764,0.29364722967147827,0.08102937042713165\n",
      "\n",
      "2022-10-01 00:34:07, Image : CheXpert-v1.0-small/valid/patient64542/study1/view1_frontal.jpg, Prob : 0.05178125575184822,0.1388433873653412,0.17289796471595764,0.29364722967147827,0.08102937042713165\n",
      "\n",
      "\n",
      "\n",
      "step  2\n",
      "CheXpert-v1.0-small/valid/patient64542/study1/view2_lateral.jpg,0.22355185449123383,0.07542623579502106,0.22232073545455933,0.17489545047283173,0.07469058036804199\n",
      "\n",
      "2022-10-01 00:34:07, Image : CheXpert-v1.0-small/valid/patient64542/study1/view2_lateral.jpg, Prob : 0.22355185449123383,0.07542623579502106,0.22232073545455933,0.17489545047283173,0.07469058036804199\n",
      "\n",
      "\n",
      "\n",
      "step  3\n",
      "CheXpert-v1.0-small/valid/patient64543/study1/view1_frontal.jpg,0.18335197865962982,0.6552352905273438,0.5845136046409607,0.3734441101551056,0.3609679639339447\n",
      "\n",
      "2022-10-01 00:34:07, Image : CheXpert-v1.0-small/valid/patient64543/study1/view1_frontal.jpg, Prob : 0.18335197865962982,0.6552352905273438,0.5845136046409607,0.3734441101551056,0.3609679639339447\n",
      "\n",
      "\n",
      "\n",
      "step  4\n",
      "CheXpert-v1.0-small/valid/patient64544/study1/view1_frontal.jpg,0.013306491076946259,0.5081664323806763,0.4156814217567444,0.3255281448364258,0.09116050601005554\n",
      "\n",
      "2022-10-01 00:34:07, Image : CheXpert-v1.0-small/valid/patient64544/study1/view1_frontal.jpg, Prob : 0.013306491076946259,0.5081664323806763,0.4156814217567444,0.3255281448364258,0.09116050601005554\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(','.join(test_header) + '\\n')\n",
    "print(\"steps\", steps, \"num_tasks\", num_tasks)\n",
    "steps = 5\n",
    "image_file = open(txt_file, \"w\")\n",
    "images = []\n",
    "\n",
    "for step in range(steps):\n",
    "    print(\"step \", step)\n",
    "    image, path = next(dataiter)\n",
    "    image = image.to(device)\n",
    "    output, __ = model(image)\n",
    "    batch_size = len(path)\n",
    "    pred = np.zeros((num_tasks, batch_size))\n",
    "\n",
    "    for i in range(num_tasks):\n",
    "        pred[i] = get_pred(output[i], cfg)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        batch = ','.join(map(lambda x: '{}'.format(x), pred[:, i]))\n",
    "        result = path[i] + ',' + batch\n",
    "        print(result + '\\n')\n",
    "        print('{}, Image : {}, Prob : {}'.format(\n",
    "            time.strftime(\"%Y-%m-%d %H:%M:%S\"), path[i], batch))\n",
    "        print('\\n\\n')\n",
    "        # image_file.write(path[i] + '\\n')\n",
    "        images.append(path[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheXpert-v1.0-small/valid/patient64541/study1/view1_frontal.jpg\n",
      "[[[  7   7   7]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [ 11  11  11]\n",
      "  [ 11  11  11]\n",
      "  [ 11  11  11]]\n",
      "\n",
      " [[  7   7   7]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [ 11  11  11]\n",
      "  [ 11  11  11]\n",
      "  [ 11  11  11]]\n",
      "\n",
      " [[  7   7   7]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [ 11  11  11]\n",
      "  [ 11  11  11]\n",
      "  [ 11  11  11]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 66  66  66]\n",
      "  [ 85  85  85]\n",
      "  [103 103 103]\n",
      "  ...\n",
      "  [ 14  14  14]\n",
      "  [ 14  14  14]\n",
      "  [ 14  14  14]]\n",
      "\n",
      " [[ 65  65  65]\n",
      "  [ 96  96  96]\n",
      "  [106 106 106]\n",
      "  ...\n",
      "  [ 14  14  14]\n",
      "  [ 14  14  14]\n",
      "  [ 14  14  14]]\n",
      "\n",
      " [[ 77  77  77]\n",
      "  [ 90  90  90]\n",
      "  [131 131 131]\n",
      "  ...\n",
      "  [ 14  14  14]\n",
      "  [ 14  14  14]\n",
      "  [ 14  14  14]]]\n",
      "[tensor([[0.4413]]), tensor([[0.0234]]), tensor([[-1.1419]]), tensor([[-0.1762]]), tensor([[-1.9679]])] []\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m jpg_file \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(jpg_file)\n\u001b[0;32m---> 27\u001b[0m prefix, figure_data \u001b[38;5;241m=\u001b[39m \u001b[43mheatmaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjpg_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m bn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(jpg_file)\n\u001b[1;32m     29\u001b[0m save_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(plot_path, prefix, bn)\n",
      "File \u001b[0;32m~/Documents/Programming_projects/Chest_CT/Chexpert/util/heatmaper.py:131\u001b[0m, in \u001b[0;36mHeatmaper.gen_heatmap\u001b[0;34m(self, image_file)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mprint\u001b[39m(logits, logit_maps)\n\u001b[1;32m    130\u001b[0m logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(logits)\n\u001b[0;32m--> 131\u001b[0m logit_maps \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(logit_maps)\n\u001b[1;32m    132\u001b[0m \u001b[39m# tensor to numpy\u001b[39;00m\n\u001b[1;32m    133\u001b[0m image_np \u001b[39m=\u001b[39m tensor2numpy(image_tensor)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "from util.heatmaper import Heatmaper \n",
    "# Heatmaper = None\n",
    "\n",
    "disease_classes = [\n",
    "    'Cardiomegaly',\n",
    "    'Edema',\n",
    "    'Consolidation',\n",
    "    'Atelectasis',\n",
    "    'Pleural Effusion'\n",
    "]\n",
    "plot_path = \"plots\"\n",
    "alpha = 0.2\n",
    "prefix = \"none\"\n",
    "\n",
    "# create plot folder\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "# construct heatmap_cfg\n",
    "heatmaper = Heatmaper(alpha, prefix, cfg, model, device)\n",
    "assert prefix in ['none', *(disease_classes)]\n",
    "with open(txt_file) as f:\n",
    "    # for line in f:\n",
    "    for line in images:\n",
    "        time_start = time.time()\n",
    "        jpg_file = line.strip('\\n')\n",
    "        print(jpg_file)\n",
    "        prefix, figure_data = heatmaper.gen_heatmap(jpg_file)\n",
    "        bn = os.path.basename(jpg_file)\n",
    "        save_file = '{}/{}{}'.format(plot_path, prefix, bn)\n",
    "        assert cv2.imwrite(save_file, figure_data), \"write failed!\"\n",
    "        time_spent = time.time() - time_start\n",
    "        print(\n",
    "            '{}, {}, heatmap generated, Run Time : {:.2f} sec'\n",
    "            .format(time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    jpg_file, time_spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv3",
   "language": "python",
   "name": "myvenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
